{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC3305 Lab Project - Time Domain Sonar Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will interact with physical time-domain signals. We will use the chirp signal to characterize the response of the speaker-microphone system and look at detecting signals using cross-correlation.\n",
    "In the second part, we will build on part one and use the speaker-microphone system to develop a simple sonar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import functions and libraries\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "import threading,time, queue, pyaudio \n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.cm as cm\n",
    "from scipy import signal\n",
    "from threading import Lock\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Chirping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When playing a sound and recording, the signal goes through several systems. In particular it goes through the response of the soundcard output, the speaker, the room we are in and the response of the microphone and receive part of the USB soundcard.\n",
    "\n",
    "A chirp is a a signal in which the frequency increases linearly with time. In this assignment we will generate a chirp signal and use it to measure the amplitude of the frequency response of our speaker-room-microphone system. This lab will work best in a quiet environment -- We recommend that you execute the lab at home or in a quiet place before submitting it. \n",
    "\n",
    "A simultaneous frequency is defined as the derivative of the phase of a signal, $f = \\frac{1}{2\\pi} \\frac{d\\phi (t)}{ dt} $. For example, the simultaneous frequency of $\\cos(\\phi(t))=\\cos(2\\pi f_0 t)$ is  \n",
    "\n",
    "$$f = \\frac{d\\phi (t)}{2\\pi dt}  = f_0$$ \n",
    "\n",
    "\n",
    "For a linear chirp, the frequency changes linearly over time. The simultaneous frequency is therefore defined as \n",
    "\n",
    "$$ f(t) = f_0 + kt. $$\n",
    "\n",
    "\n",
    "So,  \n",
    "\n",
    "$$ x(t) = \\sin(2\\pi\\int_0^t f(t')dt') = \\sin(2\\pi\\int_o^t(f_0+kt')dt') = \\sin(2\\pi(f_0+\\frac{k}{2}t)t) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I Task I: Generating the Chirp\n",
    "\n",
    "Generate a 10 seconds long chirp signal, sampled at 48,000[Hz] with a frequency range of 20[Hz] to 20,000[Hz]. Set the magnitude of the chirp to 0.5. This will help prevent non-linearities when we play the sound later. \n",
    "\n",
    "* Given $T$=total time length, $f_0$=start frequency, $f_1$ = end frequency, derive a formula $f(t)$ for the frequency sweep. Write the formula here:\n",
    "\n",
    "$$m = (f_1 - f_0)/T \\\\ f(t) = f_0 + mt \\\\ f(t) = f_0 + \\frac{f_1 - f_0}{T} t \\:\\text{Hz}$$\n",
    "\n",
    "* Find the formula for the phase by integrating $\\phi(t) = \\int_0^T f(t)dt$ to get the phase function. Write the formula here:\n",
    "\n",
    "$$\n",
    "\\frac{\\phi(t)}{2\\pi} = \\int_0^T f(t)dt \\\\ = \\int_0^T f_0 + \\frac{f_1 - f_0}{T} t dt \\\\ = f_0t + \\frac{f_1 - f_0}{2T} t^2 \n",
    "$$\n",
    "\n",
    "Now, \n",
    "* Set the sample-rate frequency `fs = 48000` Hz\n",
    "* Generate a time index from `t=0` to `t=10` with sampling rate of 48000 Hz\n",
    "* Generate a vector of frequency vs time: `phi_of_t`  (  $\\phi(t)$ )\n",
    "* Generate the chirp function `s_chirp` with amplitude of 0.5 by plugging the phase into a sinusoid. \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 48000\n",
    "f0 = 20\n",
    "f1 = 20000\n",
    "#f2 = 20\n",
    "T = 10\n",
    "# your code here\n",
    "\n",
    "A = 0.5\n",
    "\n",
    "# generate time index and phase\n",
    "t_values = np.r_[0.0:T*fs:1.0]/fs\n",
    "\n",
    "m = (f1 - f0) / T\n",
    "ft = np.vectorize(lambda t : m*t + f0)\n",
    "phi_t = np.vectorize(lambda t : m / 2 * t**2 + f0 * t)\n",
    "\n",
    "# generate chirp signal\n",
    "x_t = np.vectorize(lambda t : A*np.sin(2*np.pi * phi_t(t)))\n",
    "chirp_signal = x_t(t_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the first $\\frac{1}{2}$ second of the chirp (`s_chirp`), you will notice that the carrier frequency increases and that the chirp has a constant envelope. To get a nice figure, make sure the aspect ratio of the figure is height/width = 0.2 . Label the axis and figure appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aspect ratio such that the image is wide\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "\n",
    "#Your code below:\n",
    "half_sec_n_samples = int(0.5*fs)\n",
    "plt.plot(t_values[:half_sec_n_samples], chirp_signal[:half_sec_n_samples])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Chirp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the magnitude frequency response of the sequence from 0 to $\\pi$ using the function `signal.freqz`. Note, that the digital frequency range represents a physical frequency range of 0[hz] to 24000[Hz]. To get a nice figure, make sure the aspect ratio of the figure is height/width = 0.2. Label the axis and figure appropriately. \n",
    "\n",
    "The `signal.freqz` function can be slow -- be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate frequency response of chirp\n",
    "N = 1000\n",
    "w, h = signal.freqz(chirp_signal, worN=N)\n",
    "\n",
    "f_values = np.linspace(0,np.pi,N)\n",
    "f_gap = np.pi/N\n",
    "stop_index = int(fs/2 / f_gap)\n",
    "\n",
    "\n",
    "# generate frequency index\n",
    "f_values = w*fs/(2*np.pi)\n",
    "mag = np.absolute(h)\n",
    "\n",
    "# plot\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.plot(f_values[:stop_index], mag[:stop_index])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Chirp Frequency Response Magnitude')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why the chirp is an appropriate signal to measure the magnitude frequency response of a system. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here:\n",
    "\n",
    "We want to accurately measure the frquency response amplitude of the microphone speaker setup, which can be done using our chirp signal. This chirp allows us to see how the system can play a sound through a computer's sound card and speakers into the room before the response is recorded by the microphone and received by the sound card.\n",
    "\n",
    "The chirp has an approximately uniform magnitude over a wide range of frequencies in that it represents a rect function in the frequency domain. Therefore, we can imagine the transfer function for the system (speaker-room-microphone) simply multiplying this rect function, which is far easier to visualise and mathenmatically calculate this transfer function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I Task II: Playing and Recording the Chirp\n",
    "Now, we will play the sound of the chirp on our computer speaker and simultaneously record using the microphone. \n",
    "\n",
    "* On Apple computers it is recommended that you turn off the ambient noise reduction by going to system-preferences, selecting sound, choose the input tab and make sure that the \"Use ambient noise reduction\" box is unchecked. In some windows system there's ambient noise reduction as well. Make sure it is also turned off. \n",
    "\n",
    "* Your laptop most likely has two speakers. It is best if we work only with one. Go to the operating system's sound settings and change the stereo settings such that the speaker that is closest to the microphone is active. Your result will be much better that way. \n",
    "\t\t\n",
    "* Make sure your output volume is at 70-80% and that the laptop's microphone is on, again to avoid non-linear distorsions. \n",
    "\n",
    "* We will record 12 seconds just to make sure we capture the entire sequence. \n",
    "\n",
    "The code below defines some functions to use with pyaudio -- a multi-platform audio python interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio( Q, p, fs , dev=None):\n",
    "    # play_audio plays audio with sampling rate = fs\n",
    "    # Q - A queue object from which to play\n",
    "    # p   - pyAudio object\n",
    "    # fs  - sampling rate\n",
    "    # dev - device number\n",
    "    \n",
    "    # Example:\n",
    "    # fs = 44100\n",
    "    # p = pyaudio.PyAudio() #instantiate PyAudio\n",
    "    # Q = Queue.queue()\n",
    "    # Q.put(data)\n",
    "    # Q.put(\"EOT\") # when function gets EOT it will quit\n",
    "    # play_audio( Q, p, fs,1 ) # play audio\n",
    "    # p.terminate() # terminate pyAudio\n",
    "    \n",
    "    # open output stream\n",
    "    ostream = p.open(format=pyaudio.paFloat32, channels=1, rate=int(fs),output=True,output_device_index=dev)\n",
    "    # play audio\n",
    "    while (1):\n",
    "        data = Q.get()\n",
    "        if (data) == 'EOT' :\n",
    "            break\n",
    "        try:\n",
    "            ostream.write( data.astype(np.float32).tobytes() )\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "def record_audio( queue, p, fs ,dev=None,chunk=2048,lock=None):\n",
    "    # record_audio records audio with sampling rate = fs\n",
    "    # queue - output data queue\n",
    "    # p     - pyAudio object\n",
    "    # fs    - sampling rate\n",
    "    # dev   - device number\n",
    "    # chunk - chunks of samples at a time default 1024\n",
    "    #\n",
    "    # Example:\n",
    "    # fs = 44100\n",
    "    # Q = Queue.queue()\n",
    "    # p = pyaudio.PyAudio() #instantiate PyAudio\n",
    "    # record_audio( Q, p, fs, 1) #\n",
    "    # p.terminate() # terminate pyAudio\n",
    "    \n",
    "    istream = p.open(format=pyaudio.paFloat32, channels=1, rate=int(fs),input=True,input_device_index=dev,frames_per_buffer=chunk)\n",
    "\n",
    "    # record audio in chunks and append to frames\n",
    "    frames = [];\n",
    "    while (1):\n",
    "        try:  # when the pyaudio object is destroyed, stops\n",
    "            with lock if lock is not None else 1:\n",
    "                data_str = istream.read(chunk, exception_on_overflow=False) # read a chunk of data\n",
    "        except:\n",
    "            break\n",
    "        data_flt = np.frombuffer( data_str, 'float32' ) # convert string to float\n",
    "        queue.put( data_flt ) # append to list\n",
    "\n",
    "def xciever(sig, fs):\n",
    "    # function takes a signal and a sampling frequency\n",
    "    # it then plays and records at the same time. The function returns\n",
    "    # the recorded sound.\n",
    "\n",
    "    rcv = [];\n",
    "\n",
    "    # create an input output FIFO queues\n",
    "    Qin = queue.Queue()\n",
    "    Qout = queue.Queue()\n",
    "\n",
    "    #lock for controlling access to shared resources\n",
    "    lock = Lock()\n",
    "    \n",
    "    # create a pyaudio object\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # initialize a recording thread.\n",
    "    t_rec = threading.Thread(target = record_audio,   args = (Qin, p, fs ), kwargs={'lock': lock})\n",
    "    t_play_audio = threading.Thread(target = play_audio,  args = (Qout, p, fs  ))\n",
    "\n",
    "    # start the recording and playing threads\n",
    "    t_rec.start()\n",
    "    t_play_audio.start()\n",
    "\n",
    "    Qout.put( sig );\n",
    "    Qout.put( \"EOT\" );\n",
    "\n",
    "    # pause for RECORD_SECS seconds\n",
    "    RECORD_SECS = len(sig)/fs + 2.0\n",
    "    time.sleep( RECORD_SECS )\n",
    "    # terminate pyAudio\n",
    "    with lock:\n",
    "        p.terminate()\n",
    "        \n",
    "    # append to output\n",
    "    while ( not Qin.empty()) :\n",
    "        data = Qin.get()\n",
    "        rcv = np.append( rcv, data )\n",
    "\n",
    "    return rcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Playing and recording audio:__\n",
    "\n",
    "* Run the following code. It is an example of how to play and record sound at the same time and uses threading for the play and record threads.\n",
    "\n",
    "The resulting received sequence will be stored in the variable `rcv_chirp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lewis_000\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "## Play and record chirp at the same time\n",
    "\n",
    "fs = 48000 # sampling rate = 48000 Hz\n",
    "\n",
    "rcv_chirp = xciever( chirp_signal, fs) # Qin = queue.Queue() Qout = queue.Queue() / Note: queue instead of Queue for python3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the frequency response of the received sequence. \n",
    "* Also, plot the absolute value of the received signal. Plotting the absolute value (sort of) displays the envelope of the chirp. \n",
    "\n",
    "Label the figures and use an aspect ratio of Height/Width = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot chirp response\r\n",
    "\r\n",
    "\r\n",
    "# generate frequency response of recorded chirp\r\n",
    "w, h = signal.freqz(rcv_chirp, 1, 512)\r\n",
    "\r\n",
    "# generate frequency index\r\n",
    "freq = fs*w/(2*np.pi)\r\n",
    "\r\n",
    "# generate a time index\r\n",
    "t = np.r_[0:(len(rcv_chirp)/fs):(1/fs)]\r\n",
    "\r\n",
    "\r\n",
    "# free code for your plot:\r\n",
    "width, height = figaspect(0.2)\r\n",
    "fig1 = figure(figsize=(width,height))\r\n",
    "plt.plot(freq, abs( h ) )\r\n",
    "plt.title('Frequency response of the transceived chirp (Hz)')\r\n",
    "plt.xlabel('f[Hz]')\r\n",
    "\r\n",
    "fig1 = figure(figsize=(width,height))\r\n",
    "plt.plot(t[0:len(rcv_chirp)], abs(rcv_chirp))\r\n",
    "plt.title('Absolute value of transceived chirp');\r\n",
    "plt.xlabel('time[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comment on the results you got. In addition, what is the implicit assumption we are making in order to claim that the result is a frequency response? \n",
    "(HINT: consider the case when the chirp was very short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers here:\n",
    "\n",
    "The time response visually resembles the frequency response. This makes intuitive sense, as the frequency is made a linear function of time by the phase function. There the envelope of the chirp consists of various peaks and troughs up to 10 kHz. Beyond this, the signal reduces close to the noise floor due to the operating frequency ranges of the computer's speakers and microphones. Note that as it depends on hardware *this range would vary per system*. Below 10 kHz, certain frequencies appear to have been absorbed or reflected by the room, with absorbtion (or at least, the lack of reflection of room acoustics) characterised by the troughs. Note that the system's microphone and speaker would also contribute frequency responses in this system, however, these are unlikely to cause the troughs.\n",
    "\n",
    "The implicit assumption we are making in order to claim that the result is a frequency response is that the frequency response of the room does not change over time. For the long 10 second chirp, if the response changes during this time, the resulting measured frequency response will be a mix of different responses over the different frequency ranges (not averaged!) Thus we can only measure the response accurately when the response does not change over the 10 seconds - or in the sonar's case, where objects are not moving too fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I, Task III: Envelope detection with Hilbert transform. \n",
    "The absolute value of the of the result \"sort of\" displays the envelope, however it is still modulated by the (now rectified) frequency sweep carrier. If we write down the response, it can be expressed approximately as \n",
    "\n",
    "$$y[n] = |H[n]| \\sin(2\\pi (f_0 +k[n*T])nT + \\angle H[n])$$\n",
    "\n",
    "where $|H[n]|$ is the frequency response for the instantaneous frequency at the nth sample and $\\angle H[n]$ is its phase response. \n",
    "\n",
    "The reason that it is only an approximation is that there is an inherent assumption that we do not look at transient effects, only steady state effect for each frequency. This is a good approximation because our chirp is very slow compared to the propagation of sound in the room. \n",
    "\n",
    "One way to get the envelope $|H[n]|$ is to convert it to its analytic signal. The analytic signal $x_a(t)$ of signal $x(t)$ is:\n",
    "\n",
    "$$x_a = F^{-1}(F(x)\\cdot 2U) = x + j y$$\n",
    "\n",
    "where $F$ is the Fourier transform, $U$ the unit step function,\n",
    "and $y$ \"is\" the Hilbert transform of $x$. In other words, the negative half of the frequency spectrum is zeroed\n",
    "out, turning the real-valued signal into a complex signal.\n",
    "\n",
    "The analytic signal of the received chirp will then be: \n",
    "\n",
    "$$ y_a[n] = |H[n]|e^{j2\\pi (f_0 +k[n*T])nT + \\angle H[n]} $$\n",
    "\n",
    "The envelope can be detected by taking the magnitude. \n",
    "(analytic function of y seems to have a one more phase shift $\\pi/2$ since it is a $\\sin$ function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the analytic signal by using the function `signal.hilbert` and plot its absolute value. Note that the discrete hilbert transform is not perfect, since it uses FIR filtering. This will show up as ripple in the envelope.\n",
    "\n",
    "* Label the figures and use an aspect ration of Height/Width = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = figaspect(0.2)\r\n",
    "fig1 = figure(figsize=(width,height))\r\n",
    "\r\n",
    "## Your lovely code here:\r\n",
    "rcv_chirp_a = rcv_chirp + 1j*signal.hilbert(rcv_chirp)\r\n",
    "env = abs(rcv_chirp_a)\r\n",
    "\r\n",
    "#Create time scale\r\n",
    "t = np.r_[0:(len(env)/48000):(1/48000)]\r\n",
    "\r\n",
    "#plot:\r\n",
    "plt.plot(t[0:len(env)],  env  )\r\n",
    "plt.title('Absolute envelope of transceived chirp $|H[n]|$')\r\n",
    "plt.xlabel('time[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I, Task IV: Auto-correlation Properties of the Chirp:\n",
    "\n",
    "In part II of the lab, we will be sending and receiving chirp pulses to estimate delays between the tranceived pulses. This is done by cross correlating / matched filtering the received signal with the known chirp pulse to detect the echoes. In this task, we will investigate the correlation properties of the chirp.\n",
    "\n",
    "A cross correlation is defined as:\n",
    "\n",
    "$$ R_{xy}[n] = \\sum_{m=-\\infty}^\\infty x[m]y^*[m-n] = (x[m]*y^*[-m])[n]$$\n",
    "\n",
    ", where $y^*[-m]$ is the complex conjugat of $y[-m]$. This similar to a convolution, without flipping one of the signals. It can be implemented using a convolution as shown above. In general, the more correlated the two signals is at position $n$, the higher the value will be. That's why it is useful in a sonar system.\n",
    "\n",
    "#### Matched filter \n",
    "When we look for a very specific shape in a signal, we can compute a cross correlation between the signal and the shape we are interested in. In that case, the operation of the cross correlation is also called a matched filter -- i.e. correlating with a filter that is matched to the shape we look for. \n",
    "\n",
    "Because we will be doing cross-correlations between a chirp pulse and its echoes, it is useful to look at the auto-correlation, which is basically a cross correlation of the signal with itself. A discrete autocorrelation of a signal is defined as: \n",
    "\n",
    "$$ R_{xx}[n] = \\sum_{m=-\\infty}^\\infty x[m]x^*[m-n] = (x[m]*x^*[-m])[n]$$ \n",
    "\n",
    "The chirp has a very nice property that its auto-correlation is very narrow. Since the spread of the resulting correlation determines how fast you can detect, the width of the auto-correlation is important. This property is called pulse compression and is widely considered in radar design. Random noise and some other pseudo-random like sequences also possess this property. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a 512 sample chirp pulse with a frequency sweep from 17KHz-18KHz and sampling rate fs=48000. \n",
    "* Validate its frequency response by plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your beautiful code here:\r\n",
    "# Sampling rate and points\r\n",
    "n = 512\r\n",
    "fs = 48000\r\n",
    "T = n/fs\r\n",
    "# Frequency sweep variables \r\n",
    "f_initial = 17000\r\n",
    "f_final = 18000\r\n",
    "\r\n",
    "# generate time axis\r\n",
    "tAxis = np.r_[0:n/fs:1/fs]\r\n",
    "\r\n",
    "# generate chip signal\r\n",
    "f_of_t = (f_final - f_initial)/(2*T)*tAxis + f_initial # m*t + f0\r\n",
    "phi_of_t = 2*np.pi*f_of_t*tAxis # m*t^2 + f0\r\n",
    "s_chirp = np.sin(phi_of_t)\r\n",
    "\r\n",
    "# generate frequency response of chirp\r\n",
    "w, chirpfft = signal.freqz(s_chirp, worN=n)\r\n",
    "freqResponse = np.r_[0:n]/(2*T)\r\n",
    "\r\n",
    "\r\n",
    "# plot the signal\r\n",
    "plt.figure()\r\n",
    "width, height = figaspect(0.2)\r\n",
    "fig = figure(figsize=(width,height))\r\n",
    "plt.plot(tAxis[0:len(s_chirp)]*1000, s_chirp)\r\n",
    "plt.xlabel( \"Time (ms)\" )\r\n",
    "plt.ylabel( \"Amplitude\" )\r\n",
    "plt.title(\"512 sample chirp pulse with a frequency sweep from 17KHz-18KHz\")\r\n",
    "\r\n",
    "\r\n",
    "# Plot the FFT of the signal\r\n",
    "plt.figure()\r\n",
    "width, height = plt.figaspect(0.2)\r\n",
    "fig = plt.figure(figsize=(width,height))\r\n",
    "#plt.plot(freqResponse,chirpfft.real)\r\n",
    "#plt.plot(freqResponse,chirpfft.imag)\r\n",
    "plt.plot(freqResponse[0:len(chirpfft)],abs(chirpfft))\r\n",
    "#plt.legend([\"Real\",\"Imaginary\",\"Magnitude\"])\r\n",
    "plt.xlabel(\"frequency (kHz)\")\r\n",
    "plt.ylabel(\"Amplitude\")\r\n",
    "plt.title(\"FFT of 512 sample chirp pulse\")\r\n",
    "plt.minorticks_on()\r\n",
    "axvline(x=f_initial, color='r', linestyle='--')\r\n",
    "axvline(x=f_final, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Compute the autocorrelation of the chirp \"using\" discrete convolution, either with `signal.convolve` or `signal.fftconvolve`. Remember that you have to flip the signal since convolution does that already. You can flip a signal `x` by doing `x[::-1]`. Use mode=''full'' for convolution.\n",
    "* Plot the autocorrelation. Your plot should be spiky because we did not do envolope detection yet. Use miliseconds as the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your fantastic code here:\n",
    "\n",
    "# Flip the signal as instructed\n",
    "s_chirp_flipped = s_chirp[::-1]\n",
    "\n",
    "# Compute the autocorrelate of chirp using discrete convolution\n",
    "s_chirp_autocorrelate = signal.convolve(s_chirp, s_chirp_flipped, mode='full', method='auto')\n",
    "# Determine size of s_chirp_autocorrelate\n",
    "size = s_chirp_autocorrelate.size\n",
    "# Create new t axis for autocorrelation\n",
    "tAxisAutocorrelate = np.r_[0:size] * 1000 / fs\n",
    "\n",
    "\n",
    "# Plot the autocorrelation\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.plot(tAxisAutocorrelate, s_chirp_autocorrelate)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Autocorrelation $R_{xx}[n]$ of 512-Sample Chirp Pulse (17 kHz to 18 kHz, fs= 48 kHz)')\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.plot(tAxisAutocorrelate, np.abs(s_chirp_autocorrelate))\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Autocorrelation $|R_{xx}[n]|$ of 512-Sample Chirp Pulse (17 kHz to 18 kHz, fs= 48 kHz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way as we did before, it is possible to recover the envelope of the autocorrelation by performing a cross-correlation with the analytic signal and then taking the absolute value. In this case, we know exactly what is the analytic function is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate `s_chirp_a`, the analytic function of the chirp by computing: `s_chirp_a = exp(1j* phi_of_t )`. Perform cross correlation between `s_chirp_a` and `s_chirp` and show the envelope. As stated before, this could also be called a matched filter. \n",
    "* Measure the full-width at half max (FWHM) of the main lobe of the autocorrelation. \n",
    "* Comment on the FWHM of the main lobe of the matched-filter with respect to the length of the pulse. That ratio is also called pulse compression.  For simplicity, normalize the plot such that the maximum is 1, but record the maximum value of the autocorrelation and display it in the title of the figure.  \n",
    "\n",
    "Use the pragma ``%matplotlib notebook`` for making the figure interactive, and ``plt.grid('on')`` for displaying a grid. \n",
    "\n",
    "Use miliseconds as the x-axis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your nice script to produce beautiful chirps, xcorralations and figures here:\n",
    "s_chirp_a = np.exp(1j*phi_of_t)\n",
    "xcorr = signal.fftconvolve(s_chirp, s_chirp_a[::-1], mode='full')\n",
    "env = abs(xcorr)\n",
    "\n",
    "# max value\n",
    "max_value = np.amax(env)\n",
    "print('Max Value = ' + str(max_value))\n",
    "\n",
    "# fwhm\n",
    "peak_i = np.argmax(env)\n",
    "half_value = max_value/2\n",
    "top_half_i = np.where(env >= half_value)\n",
    "fwhm = (top_half_i[0][-1] - top_half_i[0][0])/fs *1000\n",
    "print('FWHM = %.4f ms'%fwhm)\n",
    "print('Chirp pulse length = %.4f ms'%(T*1000))\n",
    "\n",
    "# normalise\n",
    "env = env/max_value\n",
    "\n",
    "# time\n",
    "t = np.r_[0:len(env)/fs:(1/fs)]*1000\n",
    "\n",
    "# plot\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width, height))\n",
    "plt.plot(t[0:len(env)], env)\n",
    "plt.title('Envelope of the Normalised Autocorrelation of the 512-Sample Chirp Pulse. Unnormalised Maximum Value = 255.8421')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.grid('on')\n",
    "plt.minorticks_on()\n",
    "axhline(y=0.5, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "With the FWHM of 1.2083 ms and the chirp pulse length of 10.6667 ms, the FWHM of the main lobe is 11.33% of the length of the pulse, giving a pulse compression of $\\frac{10.6667\\:\\text{ms}}{1.2083\\:\\text{ms}}$ = 8.827. Thus a fair compression is achieved.\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at why the chirp pulse is better for cross-correlation detection than a pure tone.\n",
    "- Repeat Task \"III\" <- \"IV\" for:\n",
    " 1. A constant frequency of 17000Hz, 512 samples in length. \n",
    " 2. A chirp with a frequency sweep from 16500Hz - 17500Hz (1KHz Bandwidth), 512 in length.  \n",
    " 3. A chirp with a frequency sweep from 15000Hz - 19000Hz (4KHz Bandwidth), 512 in length\n",
    "- Make three subplots in one figure \n",
    "- Compare the size of the main lobes (full width at half max). How much \"Pulse Compression\" are you getting by using a chirps for detection compared to a single frequency pulse?\n",
    "- What is the approximate bandwidth of the pure frequency pulse and what is the bandwidth of the chirp pulses? Comment on the tradeoff between bandwidth and pulse compression\n",
    "- What is the maximum autocorrelation for each pulse?\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution here\n",
    "fs = 48000\n",
    "T = 512/fs\n",
    "\n",
    "t = np.r_[0:T:(1/fs)]\n",
    "\n",
    "f_0 = 17000\n",
    "phi_pure = 2*np.pi*(f_0)*t\n",
    "pure_chirp = np.sin(phi_pure)\n",
    "pure_chirp_a = np.exp(1j*phi_pure)\n",
    "pure_xcorr = abs(signal.fftconvolve(pure_chirp, pure_chirp_a[::-1], mode = 'full'))\n",
    "\n",
    "# chirp 1\n",
    "m1 = (17500-16500)/T\n",
    "t_chirp = np.r_[0:T:(1/fs)]\n",
    "phi_t1 = 2*np.pi*(16500+m1*t/2)*t\n",
    "chirp_1 = np.sin(phi_t1)\n",
    "chirp_1a = np.exp(1j*phi_t1)\n",
    "\n",
    "xcorr_1 = abs(signal.fftconvolve(chirp_1, chirp_1a[::-1], mode = 'full'))\n",
    "\n",
    "# chirp 2\n",
    "m2 = (19000-15000)/T\n",
    "phi_t2 = 2*np.pi*(15000+m2*t/2)*t\n",
    "chirp_2 = np.sin(phi_t2)\n",
    "chirp_2a = np.exp(1j*phi_t2)\n",
    "\n",
    "xcorr_2 = abs(signal.fftconvolve(chirp_2, chirp_2a[::-1],mode='full'))\n",
    "\n",
    "# Double time for correlation results:\n",
    "t = np.r_[0:2*T:(1/fs)]\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig1, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(width,height))\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=1.5)\n",
    "ax_data = ((ax1,'Pure Tone 17000Hz',pure_xcorr), (ax2,'Chirped Tone 16500Hz - 17500Hz (1KHz Bandwidth)',xcorr_1),(ax3,'Chirped Tone 15000Hz - 19000Hz (4KHz Bandwidth)',xcorr_2))\n",
    "for ax_d in ax_data:\n",
    "    axis, title, env = ax_d\n",
    "    # fwhm\n",
    "    peak_i = np.argmax(env)\n",
    "    max_value = np.amax(env)\n",
    "    half_value = max_value/2\n",
    "    top_half_i = np.where(env >= half_value)\n",
    "    fwhm = (top_half_i[0][-1] - top_half_i[0][0])/fs *1000\n",
    "    print('FWHM of %s = %.4f ms'%(title,fwhm))\n",
    "    print('Max Autocorrelation Value of %s = %.4f'%(title,max_value))\n",
    "\n",
    "    # normalise\n",
    "    env /= max_value\n",
    "\n",
    "    # plot\n",
    "    axis.plot(t[0:len(env)]*1000, env)\n",
    "    axis.set_title('Aurocorrelation of %s'%title)\n",
    "    axis.set_xlabel('Time (ms)')\n",
    "    axis.grid('on')\n",
    "    axis.axhline(y=0.5, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers and interpretations here:**\n",
    "\n",
    "FHWM results:\n",
    "* The pulse length of 512 samples at 48 kHz is 10.6667 ms\n",
    "* FWHM of Pure Tone = 10.6458 ms\n",
    "  * Pulse Compression is $\\frac{10.6667\\:\\text{ms}}{10.6458\\:\\text{ms}} = 1.002$\n",
    "* FWHM of Chirped Tone 16500Hz - 17500Hz (1KHz Bandwidth) = 1.2083 ms\n",
    "  * Pulse Compression is $\\frac{10.6667\\:\\text{ms}}{1.2083\\:\\text{ms}} = 8.828$\n",
    "* FWHM of Chirped Tone 15000Hz - 19000Hz (4KHz Bandwidth) = 0.2917 ms\n",
    "  * Pulse Compression is $\\frac{10.6667\\:\\text{ms}}{0.2917\\:\\text{ms}} = 36.567$\n",
    "\n",
    "Clearly the size of the main lobes (full width at half max) decreases as the range of frequency increases. A single frequency pulse provides negligible compression and is therefore ineffective, in contrast to the 4 kHz chirp, which provided 36.6 times compression.\n",
    "\n",
    "The pure sine pulse in the frequency domain approximately approaches a finite delta peak at 17 kHz and therefore has negligible bandwidth, compared to the pulses that have bandwidths of 1 kHz and 4 kHz respectively. Higher pulse compression requires more bandwidth to be sacrificed, thus marking the tradeoff.\n",
    "\n",
    "The maximum value of each pulse's autocorrelation is very similar. There is a small increase in maxima with decreased bandwidth, with the pure tone having the highest maxima:\n",
    "* Max Autocorrelation Value of Pure Tone 17000Hz = 255.4589\n",
    "* Max Autocorrelation Value of Chirped Tone 16500Hz - 17500Hz (1KHz Bandwidth) = 255.4352\n",
    "* Max Autocorrelation Value of Chirped Tone 15000Hz - 19000Hz (4KHz Bandwidth) = 255.3431\n",
    "\n",
    "Notably, the pure tone has higher autocorrelation overall for the total time length, judging by the area under the autocorrelation function (integration). This is obvious as a pure sinusoidal is periodic and thus more similar to itself over time in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, repeat task \"III\" <- \"IV\" for \n",
    " 1. a chirp with a frequency sweep from 15000Hz - 19000Hz, 256 in length\n",
    " 2. a chirp with a frequency sweep from 15000Hz - 19000Hz, 512 in length\n",
    "\n",
    "- Make two subplots in one figure \n",
    "- Compare the size of the main lobe (full width at half max) to the previous case of  15000Hz - 19000Hz, 512 in length.\n",
    "- Compare the maximum autocorrelation as well. \n",
    "\n",
    "What's the effect of having more bandwidth? what's the effect of having longer/shorter pulses?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution here\n",
    "fs = 48000\n",
    "T1 = 256/fs\n",
    "T2 = 512/fs\n",
    "\n",
    "time1 = np.r_[0:T1:(1/fs)]\n",
    "time2 = np.r_[0:T2:(1/fs)]\n",
    "\n",
    "# chirp 1\n",
    "m_t1 = (19000-15000)/T1\n",
    "phi_t1 = 2*np.pi*(15000+m_t1*time1/2)*time1\n",
    "chirp_t1 = np.sin(phi_t1)\n",
    "chirp_t1_a = np.exp(1j*phi_t1)\n",
    "\n",
    "xcorr_t1 = abs(signal.fftconvolve(chirp_t1, chirp_t1_a[::-1],mode='full'))\n",
    "\n",
    "# chirp 2\n",
    "m_t2 = (19000-15000)/T2\n",
    "phi_t2 = 2*np.pi*(15000+m_t2*time2/2)*time2\n",
    "chirp_t2 = np.sin(phi_t2)\n",
    "chirp_t2_a = np.exp(1j*phi_t2)\n",
    "\n",
    "xcorr_t2 = abs(signal.fftconvolve(chirp_t2, chirp_t2_a[::-1],mode='full'))\n",
    "\n",
    "# Double times for correlation results:\n",
    "time1 = np.r_[0:2*T1:(1/fs)]\n",
    "time2 = np.r_[0:2*T2:(1/fs)]\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(width,height))\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=1.5)\n",
    "ax_data = ((ax1,'Chirped Tone 256 samples (4 kHz Bandwidth)',xcorr_t1,time1), (ax2,'Chirped Tone 512 samples (4 kHz Bandwidth)',xcorr_t2,time2))\n",
    "for ax_d in ax_data:\n",
    "    axis, title, env, t = ax_d\n",
    "    # fwhm\n",
    "    peak_i = np.argmax(env)\n",
    "    max_value = np.amax(env)\n",
    "    half_value = max_value/2\n",
    "    top_half_i = np.where(env >= half_value)\n",
    "    fwhm = (top_half_i[0][-1] - top_half_i[0][0])/fs *1000\n",
    "    print('FWHM of %s = %.4f ms'%(title,fwhm))\n",
    "    print('Max Autocorrelation Value of %s = %.4f'%(title,max_value))\n",
    "\n",
    "    # normalise\n",
    "    env /= max_value\n",
    "\n",
    "    # plot\n",
    "    axis.plot(t[0:len(env)]*1000, env)\n",
    "    axis.set_title('Aurocorrelation of %s'%title)\n",
    "    axis.set_xlabel('Time (ms)')\n",
    "    axis.grid('on')\n",
    "    axis.axhline(y=0.5, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Your answer below:\n",
    "\n",
    "FWHM results:\n",
    "* FWHM of Chirped Tone 256 samples (4 kHz Bandwidth) = 0.2917 ms\n",
    "* FWHM of Chirped Tone 512 samples (4 kHz Bandwidth) = 0.2917 ms\n",
    "\n",
    "Max Autocorrelation Value results:\n",
    "* Max Autocorrelation Value of Chirped Tone 256 samples (4 kHz Bandwidth) = 127.9086\n",
    "* Max Autocorrelation Value of Chirped Tone 512 samples (4 kHz Bandwidth) = 255.3431\n",
    "\n",
    "The FWHM size of the main lobe for both pulses of size 256 and 512 samples is equal. Thus, halfing the length of the pulse has no effect on the compression ratio. The maximum autocorrelation differed dramatically compared to the previous section, with the 256-sample pulse resulting in half as much autocorrelation as the 512-sample pulse.\n",
    "\n",
    "#### Summary\n",
    "In summary, having more bandwidth decreases the FWHM of the main lobe and hence increases the pulse compression, while having longer/shorter pulses results in increased/decreased autocorrelation magnitude at these peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with sidelobes\n",
    "As you can see, the chirp provides good pulse compression of the main-lobe. However, there exists very strong sidelobes. This is because the chirp is multiplied with a rect function, that is abrupt. Instead, we will window the chirp with one of the smooth window functions to taper off the sidelobes. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat the above for a chirp with a sweep from 16.5KHz to 17.5KHz, and from 15KHz to 19KHz. This time, multiply the chirp (and its analytic function) with a hanning window.  You will find the function `np.hanning` useful. \n",
    "\n",
    "* plot the normalized autocorrelations (in the same figure) \n",
    "* Comment on the magnitude of the side-lobes? \n",
    "* Comment on the width of the main lobes? \n",
    "* What's the tradeoff?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your solution here\n",
    "fs = 48000\n",
    "T = 512/fs\n",
    "\n",
    "t = np.r_[0:T:(1/fs)]\n",
    "\n",
    "# chirp 1\n",
    "m1 = (17500-16500)/T\n",
    "t_chirp = np.r_[0:T:(1/fs)]\n",
    "phi_t1 = 2*np.pi*(16500+m1*t/2)*t\n",
    "chirp_1 = np.sin(phi_t1) * np.hanning(T*fs)\n",
    "chirp_1a = np.exp(1j*phi_t1) * np.hanning(T*fs)\n",
    "\n",
    "xcorr_1 = abs(signal.fftconvolve(chirp_1, chirp_1a[::-1], mode = 'full'))\n",
    "\n",
    "# chirp 2\n",
    "m2 = (19000-15000)/T\n",
    "phi_t2 = 2*np.pi*(15000+m2*t/2)*t\n",
    "chirp_2 = np.sin(phi_t2) * np.hanning(T*fs)\n",
    "chirp_2a = np.exp(1j*phi_t2) * np.hanning(T*fs)\n",
    "\n",
    "xcorr_2 = abs(signal.fftconvolve(chirp_2, chirp_2a[::-1],mode='full'))\n",
    "\n",
    "# Double time for correlation results:\n",
    "t = np.r_[0:2*T:(1/fs)]\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(width,height))\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=1.5)\n",
    "ax_data = ((ax1,'Chirped Tone 16500Hz - 17500Hz (1KHz Bandwidth)',xcorr_1),(ax2,'Chirped Tone 15000Hz - 19000Hz (4KHz Bandwidth)',xcorr_2))\n",
    "for ax_d in ax_data:\n",
    "    axis, title, env = ax_d\n",
    "    # fwhm\n",
    "    peak_i = np.argmax(env)\n",
    "    max_value = np.amax(env)\n",
    "    half_value = max_value/2\n",
    "    top_half_i = np.where(env >= half_value)\n",
    "    fwhm = (top_half_i[0][-1] - top_half_i[0][0])/fs *1000\n",
    "    print('FWHM of %s = %.4f ms'%(title,fwhm))\n",
    "    print('Max Autocorrelation Value of %s = %.4f'%(title,max_value))\n",
    "\n",
    "    # normalise\n",
    "    env /= max_value\n",
    "\n",
    "    # plot\n",
    "    axis.plot(t[0:len(env)]*1000, env)\n",
    "    axis.set_title('Aurocorrelation of %s With Hanning Window'%title)\n",
    "    axis.set_xlabel('Time (ms)')\n",
    "    axis.grid('on')\n",
    "    axis.axhline(y=0.5, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answers here:\n",
    "\n",
    "Results:\n",
    "* FWHM of Chirped Tone 16500Hz - 17500Hz (1KHz Bandwidth) = 2.4583 ms\n",
    "* FWHM of Chirped Tone 15000Hz - 19000Hz (4KHz Bandwidth) = 0.6250 ms\n",
    "* Max Autocorrelation Value of Chirped Tone 16500Hz - 17500Hz (1KHz Bandwidth) = 95.8125\n",
    "* Max Autocorrelation Value of Chirped Tone 15000Hz - 19000Hz (4KHz Bandwidth) = 95.8125\n",
    "\n",
    "The width of the main lobe is doubled:\n",
    "* 2.4583 ms vs. 1.2083 ms\n",
    "* 0.6250 ms vs. 0.2917 ms\n",
    "\n",
    "The maximum autocorrelation is reduced:\n",
    "* 95.8125 vs. 255.4352\n",
    "* 95.8125 vs. 255.3431\n",
    "\n",
    "But, the sidelobes are significantly smaller! Thus we tradeoff both width and maximum autocorrelation for no sidelobes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are now ready to proceed to the Sonar Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the lab we will write a simple application that implements a sonar using the laptop internal speaker and microphone. \n",
    "\n",
    "The basic idea is very simple and is the basis of sonar and ultrasound images -- Objects reflect sound waves. If we send a pulse of sound, we will get reflection echoes of that pulse. Detecting the echos and their time-of-flight will reveal their distance from the source, based on the speed of sound in air. \n",
    "\n",
    "The way we are going to implement the sonar is to generate a series of rapid pulses, and use matched filtering to detect the source and the returning echos. There are many parameters in this lab that can be tweaked to get different results. We encourage you to experiment. We hope you enjoy this. \n",
    "\n",
    "\n",
    "#### Instructions for laptops:\n",
    "\n",
    "Unfortunately, the quallity of the sonar system is going to be highly dependent on your laptop quallity, and the position of the speakers and microphone. It is recommended that you adjust the sound settings on your system such that only the speaker that is closer to the microphone is active. For example, MacBookAirs have the microphone on the side of the computer -- so you should set adjust the audio settings to left speaker only. Also, it is recommended that the speaker volume be set to half of its maximum to avoid non-linear distortions.  \n",
    "\n",
    "If you are getting poor results, please consult with us. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II, Task I: Generating Chirp Pulses\n",
    "\n",
    "Recall from Part I, that the with of the main lobe of the autocorrelation depends on the bandwidth of the pulse. \n",
    "For a constant frequency pulse, the bandwidth will be inversly proportional to its length. Short pulses are localized in time, and therefore we will be able to separate echoes from targets that are close. However, short pulses carry less energy (for the same amplitude) and this will reduce our signal to noise ratio (SNR) in the detection and reduce our ability to detect the targets at all. So, in summary: for a constant frequency pulse, there's an inherent tradeoff between the resolution of the sonar (distinguish between close targets) and the signal to noise ratio. \n",
    "\n",
    "If we use a chirp pulse, we can increase the length of the pulse while also increasing the bandwidth. This will enable us to improve our signal to noise ratio as well as keeping the resolution of our sonar (by preserving the BW).\n",
    "\n",
    "In our implemetation we are going to design a pulsed sonar system in which we repeatedly send pulses and then listen to the returning echoes. The arrival time of the echos will correspond to double the time-of-flight of sound propagation from our system to the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a function that generates a chirp pulse:\n",
    "`pulse = genChirpPulse(Npulse, f0, f1, fs)` \n",
    "\n",
    "The function will accept: `Npulse` = number of samples, `f0,f1` = starting and ending frequency and `fs` = sampling frequency. The function will return the analytic function of the chirp $\\exp (j 2\\pi \\int_0^t f(t)dt )$ with amplitude 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genChirpPulse(Npulse, f0, f1, fs):\n",
    "    #     Function generates an analytic function of a chirp pulse\n",
    "    #     Inputs:\n",
    "    #             Npulse - pulse length in samples\n",
    "    #             f0     - starting frequency of chirp\n",
    "    #             f1     - end frequency of chirp\n",
    "    #             fs     - sampling frequency\n",
    "    #     Output:\n",
    "    #              pulse - chirp pulse\n",
    "    \n",
    "    # Create time axis\n",
    "    tAxis = np.r_[0:Npulse]/fs\n",
    "\n",
    "    # Create f(t) function \n",
    "    ft = ((f1 - f0) / ( 2 * (Npulse/fs)) ) * tAxis + f0\n",
    "\n",
    "    # Analytic chirp response with amp 1\n",
    "    pulse = np.exp(1j * 2 * np.pi * ft * tAxis)\n",
    "    \n",
    "    return pulse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* To validate that the function works display the pulse generated with Npulse = 200, f0=1000, f1 = 8000, fs = 48000. Remember the pulse is complex, so plot the real and imaginary part separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\r\n",
    "Npulse = 200\r\n",
    "f0 = 1000\r\n",
    "f1 = 8000\r\n",
    "fs = 48000\r\n",
    "\r\n",
    "# As provided\r\n",
    "pulse = genChirpPulse(Npulse, f0, f1, fs)\r\n",
    "\r\n",
    "# Create time axis\r\n",
    "tAxis = np.r_[0:Npulse]/fs\r\n",
    "\r\n",
    "width, height = plt.figaspect(0.2)\r\n",
    "fig = plt.figure(figsize=(width,height))\r\n",
    "plt.title(\"Real Plot\")\r\n",
    "plt.xlabel(\"N\")\r\n",
    "plt.ylabel(\"Amplitude\")\r\n",
    "plt.plot(tAxis[0:len(pulse)], np.real(pulse))\r\n",
    "\r\n",
    "\r\n",
    "width, height = plt.figaspect(0.2)\r\n",
    "fig = plt.figure(figsize=(width,height))\r\n",
    "plt.title(\"Imaginary Plot\")\r\n",
    "plt.xlabel(\"N\")\r\n",
    "plt.ylabel(\"Amplitude\")\r\n",
    "plt.plot(tAxis, np.imag(pulse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generate Pulse Trains__\n",
    "\n",
    "Next, we will use the pulse generated by `genChirpPulse` and generate a pulse train.\n",
    "\n",
    "* Write a new function `ptrain = genPulseTrain(pulse, Nrep, Nseg)`\n",
    "The function accepts `pulse` = a pulse generated by `genChirpPulse`,  `Nrep` = number of pulse repetitions and `Nseg` = length of each pulse train segment (which is >= to the length of `pulse`).\n",
    "\n",
    "The function returns `ptrain` which is a vector of length `Nrep` x `Nseg` (Hint: use `np.tile`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genPulseTrain(pulse, Nrep, Nseg):\n",
    "    # Funtion generates a pulse train from a pulse. \n",
    "    #Inputs:\n",
    "    #    pulse = the pulse generated by genChirpPulse\n",
    "    #    Nrep  =  number of pulse repetitions\n",
    "    #    Nseg  =  Length of pulse segment >= length(pulse)\n",
    "    \n",
    "    pulse = np.append(pulse, np.zeros(Nseg - len(pulse)))\n",
    "    ptrain = np.tile(pulse, Nrep)\n",
    "    \n",
    "    return ptrain\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II, Task II: Echos in with Chirp pulse train\n",
    "\n",
    "We now have components to generate pulses, generate a pulse train, play and record it. Lets see what we get!\n",
    "We will start with very short pulses with a single carrier frequency. Rectangular pulses are difficult for the speaker\n",
    "to produce as they exhibit discontinuities in the beginning and the end of the pulse. Therefore we will multiply the pulses\n",
    "with a smooth window. Here, we will use a hanning window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a f0=f1=8KHz, Npulse=96 pulse with fs=48000. Window the pulse with a hanning window. This will result in a pulse length of 2ms. You should be able to hear this tone.\n",
    "* Plot the real and imaginary part of the pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 48000\n",
    "f0 = 8000\n",
    "f1 = 8000\n",
    "Npulse = 96\n",
    "\n",
    "# your code here:\n",
    "\n",
    "# Create windowpulse with genChirp function - leverage np.hanning function\n",
    "windowPulse = genChirpPulse(Npulse, f0, f1, fs)*np.hanning(Npulse)\n",
    "\n",
    "# Create time axis\n",
    "tAxis = np.r_[0:Npulse]\n",
    "\n",
    "realWindowPulse = np.real(windowPulse)\n",
    "imagWindowPulse = np.imag(windowPulse)\n",
    "\n",
    "# Create figure for real function\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Windowed Chirp Pulse - Real\")\n",
    "plt.plot(tAxis/fs * 1000, realWindowPulse)\n",
    "\n",
    "# Create figure for imaginary function\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.xlabel(\"Samples (N)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Windowed Chirp Pulse - Imaginary\")\n",
    "plt.plot(tAxis, imagWindowPulse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the real part of the pulse to generate a pulse train of Nrep=15 pulses, Nseg=4096 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "Nrep = 15\n",
    "Nseg = 4096\n",
    "\n",
    "# Use previous 'realWindowPulse' function\n",
    "realPulseTrain = genPulseTrain(realWindowPulse, Nrep, Nseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Play and record the pulse train. Scale the amplitude of the pulses to 1/2. Make sure your volume is set to maximum of 70% and look at the plot with the input pulse train and the received pulse train.\n",
    "\n",
    "Use the pragma ``%matplotlib notebook`` for interactive plots, so you can zoom into the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lewis_000\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "# Scaling amplitude of the pulses to 1/2\n",
    "rcv = xciever(realPulseTrain/2.0, fs) \n",
    "\n",
    "# I get error here: <ipython-input-18-74cf6cae67c5>:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
    "# me too, still works tho - Lewis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = plt.figaspect(0.2)\r\n",
    "fig = plt.figure(figsize=(width,height))\r\n",
    "\r\n",
    "tAxis = np.r_[0:len(rcv)]/fs\r\n",
    "# Plot generated pulse train\r\n",
    "plt.plot(tAxis[0:len(realPulseTrain)], realPulseTrain/2.0,color='r')\r\n",
    "\r\n",
    "# Plot received pulse train audio\r\n",
    "plt.plot(tAxis[0:len(rcv)],rcv,color='k')\r\n",
    "\r\n",
    "plt.xlabel(\"Time (s)\")\r\n",
    "plt.ylabel(\"Magnitude\")\r\n",
    "plt.title(\"Transmitted and Received Pulse Train\")\r\n",
    "plt.legend([\"Transmitted Pulse Train (Speaker)\", \"Received Pulse Train (Mic)\"],loc=1)\r\n",
    "plt.minorticks_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract a single pulse from the received pulse train. You can find the pulse index from the interactive plot. Extract at least 2 Npulse samples before the pulse and 20 Npulse samples after using `rcv_pulse = rcv[idx-2*Npulse:idx+Npulse*20]` \n",
    "\n",
    "* Plot the received pulse. Can you see any echoes?\n",
    "\n",
    "You can disable interactivity by the pragma ``matplotlib inline``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\r\n",
    "\r\n",
    "# your code here:\r\n",
    "NPulseSamples = 20\r\n",
    "NPulseExtract = 2\r\n",
    "# Estimate of pulse - couldn't get the interactive chart to work.\r\n",
    "\r\n",
    "id_second = 0.62 # ENTER the time before a pulse in seconds <<--\r\n",
    "\r\n",
    "idx = int(id_second*fs) # idx = 14000\r\n",
    "# find index of start pulse - idx and Npulse params already set\r\n",
    "rcv_pulse = rcv[idx-NPulseExtract*Npulse:idx+Npulse*NPulseSamples]\r\n",
    "\r\n",
    "# make plot\r\n",
    "width, height = plt.figaspect(0.2)\r\n",
    "fig = plt.figure(figsize=(width,height))\r\n",
    "plt.xlabel(\"Time (ms)\")\r\n",
    "plt.ylabel(\"Magnitude\")\r\n",
    "plt.title(\"Single Pulse from Pulse Train\")\r\n",
    "timeAxis = np.r_[idx-NPulseExtract*Npulse:idx+Npulse*NPulseSamples]/fs *1000\r\n",
    "plt.plot(timeAxis[0:len(rcv_pulse)], rcv_pulse)\r\n",
    "plt.minorticks_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some echo is visible, trailing the main pulse, with around the same length of the pulse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matched Filtering\n",
    "\n",
    "The strong pulses we see are a result of direct feed-through from the transmitter to the receiver that do not scatter off targets. The echoes we see are a result of echoes from reflecting surfaces. The problem in our setup is that we don't know the exact delay between the transmitter and the receive hardware (in PyAudio). Instead, we will assume that the travel time for sound between the speaker and the microphone is negligible and much smaller than scatering targets. We can then detect when the pulses start based on the direct feedthrough signal. This assumption is very good as long as your speaker is close to the microphone!\n",
    "\n",
    "We will detect both the feedthrough and echoes using matched filtering. \n",
    "\n",
    "* Write a function `Xrcv = crossCorr( rcv, pulse_a )` to calculate the cross correlation (matched filter) of the received signal with the analytic function of the pulse.  You can use `signal.fftconvolve`\n",
    "* Take the absolute value of `Xrcv` to recover its envelope. Call the result `Xrcv_a`.\n",
    "\n",
    "Make sure the plot is interactive with ``matplotlib notebook``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossCorr( rcv, pulse_a ):\n",
    "    # Funtion generates cross-correlation between rcv and pulse_a\n",
    "    # Inputs:\n",
    "    #    rcv - received signal\n",
    "    #    pulse_a - analytic pulse\n",
    "    # Output:\n",
    "    #    Xrcv - cross-correlation between rcv and pulse_a\n",
    "    Xrcv = signal.fftconvolve(rcv, pulse_a[::-1])\n",
    "    return Xrcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\r\n",
    "pulse_a = windowPulse\r\n",
    "# Call cross correlation (matched filter)\r\n",
    "Xrcv = crossCorr(rcv, pulse_a)\r\n",
    "Xrcv_a = abs(Xrcv)\r\n",
    "\r\n",
    "tAxis = np.r_[0:len(Xrcv_a)]/fs\r\n",
    "\r\n",
    "width, height = plt.figaspect(0.2)\r\n",
    "fig = plt.figure(figsize=(width,height))\r\n",
    "plt.xlabel(\"Time (s)\")\r\n",
    "plt.ylabel(\"Magnitude\")\r\n",
    "plt.title(\"Matched-filtered Received Pulse Train\")\r\n",
    "plt.minorticks_on()\r\n",
    "plt.plot(tAxis[0:len(Xrcv_a)], Xrcv_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Again, extract a single pulse from the received pulse train using the same index. Extract at least 2 Npulse samples before the pulse and 20 Npulse samples after. Plot the received pulse. Can you see any echoes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPulseSamples = 20\n",
    "NPulseExtract = 2\n",
    "\n",
    "id_second = 0.62 # ENTER the time before a pulse in seconds <<--\n",
    "\n",
    "idx = int(id_second*fs)\n",
    "\n",
    "Xrcv_a_pulse = Xrcv_a[idx-NPulseExtract*Npulse:idx+Npulse*NPulseSamples]\n",
    "\n",
    "# plot\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Single Pulse from Natched-Filtered Pulse Train\")\n",
    "timeAxis = np.r_[idx-NPulseExtract*Npulse:idx+Npulse*NPulseSamples]/fs *1000\n",
    "plt.plot(timeAxis, Xrcv_a_pulse)\n",
    "plt.minorticks_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal is far cleaner. The previously observed echoes still seem to be present in the form of a side-peak to the right of the main peak. This side-lobe is almost 5 times smaller than the main peak and would vary dramatically depending on the computer hardware setup used and nature of the room environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sonar System\n",
    "\n",
    "In order to automate the system and visualize the results we need a few more components. To extract the pulses we need to know the position of the first feedthrough pulse. \n",
    "\n",
    "\n",
    "* Write a function `idx = findDelay(Xrcv_a, Nseg)` that takes the result of the matched filtering and finds the index of the first feedthrough pulse. Try testing on the actual signal to check whether the function is correct. There are multiple ways of doing it. `Nseg` is not necessarily required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDelay(Xrcv, Nseg):\n",
    "    # finds the first pulse\n",
    "    # Inputs:  \n",
    "    #         Xrcv - the received matched filtered signal\n",
    "    #         Nseg - length of a segment\n",
    "    # Output:\n",
    "    #          idx - index of the beginning of the first pulse\n",
    "    peaks, properties = signal.find_peaks(Xrcv,prominence = 0.6)\n",
    "    return peaks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = findDelay(Xrcv_a,Nseg)\n",
    "\n",
    "# Plot an 'x' to mark the first peak at 'idx' :\n",
    "tAxis = np.r_[0:len(Xrcv_a)]/fs\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Matched-filtered Received Pulse Train\")\n",
    "plt.minorticks_on()\n",
    "plt.plot(tAxis, Xrcv_a)\n",
    "plt.plot(idx/fs, Xrcv_a[idx],'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can correct for delays and detect echoes. The only thing left now is to convert the time between echoes into actual distance.\n",
    "\n",
    "If we send a pulse of sound, we will get reflection echoes of that pulse. Detecting the echos and their time-of-flight will reveal their distance from the source, based on the speed of sound in air. The speed of sound in air is given by the following equation:\n",
    "\n",
    "$$ v_s = 331.5\\sqrt{1+T/273.15}~\\mathrm{m/s}~,$$ \n",
    "\n",
    "where T is the temperature in degree celcius. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function `t = dist2time( dist, temperature )` that takes in the distance to the target in cm and converts it into the time in seconds between the transmitted pulse and its echo. Remember the arrival time include the time to the target and back and therefore the time should be doubled. \n",
    "For example, for temperature = 20 celcius and dist = 400 cm, the time it takes is 0.023 secs.\n",
    "\n",
    "* Create a function `dist = time2dist( t, temperature )` that takes in the time to the target in seconds and converts it into the distance in cm between the transmitted pulse and its echo. Remember the arrival time include the time to the target and back and therefore the time should be halfed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dist2time( dist, temperature=21):\n",
    "    # Converts distance in cm to time in secs\n",
    "    # Inputs:\n",
    "    # dist        - distance to object in cm\n",
    "    # temperature - in celcius\n",
    "    # Output:\n",
    "    # t           - time in seconds between transmitted pulse and echo\n",
    "    v_s = 331.5*np.sqrt(1+temperature/273.15)\n",
    "    d_metres = dist/100 # cm to m\n",
    "    return 2*d_metres/v_s\n",
    " \n",
    "\n",
    "def  time2dist(t,temperature=21):\n",
    "    # Converts time in seconds to distance in cm\n",
    "    # Inputs:\n",
    "    # t        - time of echo\n",
    "    # temperature - in celcius\n",
    "    # Output:\n",
    "    # dist          - distance in cm of the target\n",
    "    v_s = 331.5*np.sqrt(1+temperature/273.15)\n",
    "    return (t/2)*v_s *100 # cm\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02329496742157036\n",
      "400.0\n"
     ]
    }
   ],
   "source": [
    "t = dist2time(400, 20)\n",
    "print(t)\n",
    "\n",
    "dist = time2dist(t, 20)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sonar (almost)\n",
    "\n",
    "* The following function will use your functions to generate pulses and display the matched filtering of each pulse as intensity of a horizontal line in an image. If nothing is moving, you will be able to see constant vertical lines representing echos. If something is moving, you will be able to track the object's distance.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some code for you\n",
    "\n",
    "def sortOfASonar(Npulse, f0, f1,fs, Nrep, Nseg):\n",
    "    pulse_a = genChirpPulse(Npulse, f0, f1, fs)\n",
    "    hanWin = np.hanning(Npulse)\n",
    "    hanWin = np.reshape(hanWin, (Npulse,1))\n",
    "    pulse_a = np.multiply(pulse_a,hanWin)\n",
    "    pulse = np.real(pulse_a)\n",
    "    ptrain = genPulseTrain(pulse, Nrep, Nseg)\n",
    "    rcv = xciever(ptrain/2.0 , fs) \n",
    "    Xrcv_a = abs( crossCorr(rcv, pulse_a) )\n",
    "    Xrcv_a = np.reshape(Xrcv_a, (1,len(Xrcv_a)))\n",
    "    \n",
    "    idx = findDelay(Xrcv_a,Nseg) \n",
    "    img = np.zeros((Nrep,Nseg))\n",
    "    img[0,:] = Xrcv_a[0,idx:idx+Nseg]\n",
    "    \n",
    "    # Look for peak in each pulse in the pulse train to avoid drift between xmit and receive\n",
    "    for n in range(1,Nrep):\n",
    "       idxx = findDelay(Xrcv_a[0,idx+int(Nseg/2):idx+int(Nseg/2)+Nseg],Nseg)\n",
    "       idx = idx + idxx + int(Nseg/2)\n",
    "       img[n,:]=Xrcv_a[0,idx:idx+Nseg]\n",
    "        \n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the function above to:  \n",
    "\n",
    "* Generate a pulse train of 100 pulses. Each (hamming windowed) pulse should be length of 72 samples (1.5ms) and constant frequency of 8KHz. The spacing between puslses should be 0.1 seconds (Nseg=4800). \n",
    "* Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lewis_000\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "Npulse = 72\n",
    "f0 = 8000\n",
    "f1 = 8000\n",
    "fs = 48000\n",
    "Nrep = 100\n",
    "Nseg = 4800\n",
    "\n",
    "img = sortOfASonar(Npulse, f0, f1,fs, Nrep, Nseg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result. Pay attention to the width of the echos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# display up to 2.5m approximately 700 samples at 21 degrees C in 48000 sampling rate\n",
    "\n",
    "vmax = 0.3 # threshold -- lower will be able to see smaller echos\n",
    "\n",
    "plt.imshow(img[:,0:700]/max(img.ravel()),vmax=vmax, aspect=10,cmap='gray',interpolation='bilinear',extent=(0,time2dist(700/48000),Nrep*Nseg/fs,0))\n",
    "plt.xlabel('cm')\n",
    "plt.ylabel('sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, repeat the experiment with a chirp length of Nseg = 360 samples, and a frequency sweep from 6KHz to 12KHz.\n",
    "Pay attention to the resolution of the lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npulse = 72*5\n",
    "f0 = 6000\n",
    "f1 = 12000\n",
    "fs = 48000\n",
    "Nrep = 100\n",
    "Nseg = 4800\n",
    "img = sortOfASonar(Npulse, f0, f1,fs, Nrep, Nseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f6ebb7c7bb65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m \u001b[0;31m# threshold -- lower will be able to see smaller echos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime2dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m48000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNrep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mNseg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# display up to 2.5m approximately 700 samples at 21 degrees C in 48000 sampling rate\n",
    "\n",
    "vmax = 0.3 # threshold -- lower will be able to see smaller echos\n",
    "\n",
    "plt.imshow(img[:,0:700]/max(img.ravel()),vmax=0.2, aspect=10,cmap='gray',interpolation='bilinear',extent=(0,time2dist(700/48000),Nrep*Nseg/fs,0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to repeat while moving a target-- can you see the echoes changing? Try playing with different parameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## A Real (time) Sonar\n",
    "You now have a working sonar! It would be much easier though to play with different parameters if we automate things, so we created some wrappers for real-time plotting in a separate notebook (lab1-RealTime-Sonar). \n",
    "\n",
    "* Copy-and-paste the 5 functions you created, including genPulseTrain(), genChirpPulse(), crossCorr(), findDelay(), and dist2time(), to the specified code cell in the real-time Sonar lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are now ready to proceed to the Real-Time Sonar Lab"
   ]
  }
 ],
 "metadata": {
  "language_info": {},
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}